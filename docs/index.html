<!DOCTYPE html>
<html lang="fa">
<head>
  <meta charset="utf-8">
  <meta name="description" content="IRL-DAL: Safe and Adaptive Trajectory Planning for Autonomous Driving via Energy-Guided Diffusion Models">
  <meta name="keywords" content="IRL-DAL, Autonomous Driving, Diffusion Models, Inverse Reinforcement Learning, Trajectory Planning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>IRL-DAL: Safe and Adaptive Trajectory Planning for Autonomous Driving</title>

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  
  <!-- Bulma CSS -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
  
  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
  
  <!-- Academicons -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  
  <!-- jQuery -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  
  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <!-- Custom CSS -->
  <style>
    /* Custom Styles for IRL-DAL */
    .dnerf { 
      color: #0066cc; 
      font-weight: bold; 
    }
    
    .publication-title {
      font-family: 'Google Sans', sans-serif;
      font-weight: 400;
    }
    
    .author-block {
      display: inline-block;
      margin-right: 5px;
    }
    
    .author-block a {
      color: #0066cc;
      text-decoration: none;
    }
    
    .author-block a:hover {
      text-decoration: underline;
    }
    
    .publication-links .link-block {
      display: inline-block;
      margin: 5px;
    }
    
    .carousel {
      overflow: hidden;
      position: relative;
    }
    
    .carousel .item {
      display: none;
      width: 100%;
    }
    
    .carousel .item.active {
      display: block;
    }
    
    .interpolation-image {
      max-width: 100%;
      height: auto;
    }
    
    .slider {
      margin: 20px 0;
    }
    
    table {
      margin: 20px 0;
    }
    
    .table.is-selected {
      background-color: #f0f8ff;
    }

    /* Highlight selected row text */
    .table.is-selected, 
    .table.is-selected td {
        color: #000; 
    }
    
    .image.is-fullwidth {
      width: 100%;
      height: auto;
    }
    
    /* Zoom effect on video in abstract section */
    figure.is-pulled-right video {
      transition: transform 0.3s ease, box-shadow 0.3s ease;
      cursor: pointer;
      border-radius: 8px;
    }

    figure.is-pulled-right video:hover {
      transform: scale(1.05);
      box-shadow: 0 8px 24px rgba(0, 0, 0, 0.3);
    }
    
    /* Zoom effect on all images */
    .image,
    figure img {
      transition: transform 0.3s ease, box-shadow 0.3s ease;
      cursor: pointer;
      border-radius: 8px;
    }

    .image:hover,
    figure img:hover {
      transform: scale(1.05);
      box-shadow: 0 8px 24px rgba(0, 0, 0, 0.3);
    }
    
    .publication-video iframe {
      width: 100%;
      height: 400px;
    }
    
    .navbar-item img {
      width: 1.2em;
      height: 1.2em;
    }
    
    .navbar-burger {
      color: #4a4a4a;
    }
    
    .navbar-burger:hover {
      background-color: transparent;
    }
    
    .video-container video {
      transition: transform 0.3s ease, box-shadow 0.3s ease;
    }
    
    .video-container video:hover {
      transform: scale(1.03);
      box-shadow: 0 8px 24px rgba(0, 0, 0, 0.2);
    }

    /* Helper for red percentage text */
    .pct-improve {
        color: #cc0000;
        font-size: 0.9em;
        margin-left: 4px;
    }
  </style>
</head>

<body>
  <!-- Navigation -->
  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false" data-target="navMenu">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <!-- <div class="navbar-menu" id="navMenu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item" href="https://aut.ac.ir">
          <span class="icon">
            <i class="fas fa-home"></i>
          </span>
        </a>
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">More Research</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://arxiv.org">arXiv</a>
            <a class="navbar-item" href="https://github.com">GitHub</a>
          </div>
        </div>
      </div>
    </div> -->
  </nav>

  <!-- Hero Section -->
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              IRL-DAL: Safe and Adaptive Trajectory Planning for Autonomous Driving via Energy-Guided Diffusion Models
            </h1>
                        
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://orcid.org/0009-0007-6572-6688" target="_blank">
                  Seyed Ahmad Hosseini Miangoleh
                </a><sup>1</sup>,
              </span>

              <span class="author-block">
                <a href="https://orcid.org/0009-0003-8482-1219" target="_blank">
                  Amin Jalal Aghdasian
                </a><sup>1</sup>,
              </span>

              <span class="author-block">
                <a href="https://orcid.org/0000-0003-4957-987X" target="_blank">
                  Farzaneh Abdollahi
                </a><sup>1</sup>
              </span>

              <div class="affiliation is-size-5">
                <span class="author-affiliation">
                  <sup>1</sup>Department of Electrical Engineering, Amirkabir University of Technology (Tehran Polytechnic), Tehran, Iran
                </span>
              </div>
            </div>


            <div class="publication-links">
              <span class="link-block">
                <a href="IRL_DAL_Safe_and_Adaptive_Trajectory_Planning_for_Autonomous_Driving.pdf" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fas fa-file-pdf"></i></span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/Seyed07/Autonomous-Driving-via-Hybrid-Learning-and-Diffusion-Planning" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fab fa-github"></i></span>
                  <span>Code</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Architecture Overview Section -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full has-text-centered">
          <h2 class="title is-3">Architecture Overview</h2>
          <div class="content">
            <p>
              The <span class="dnerf">IRL-DAL</span> framework integrates four core components: a hybrid IL-IRL-RL training curriculum, 
              an energy-guided diffusion planner, a learnable adaptive mask for contextual perception, and a safety-aware experience correction mechanism.
            </p>
            <img src="main.png" alt="IRL-DAL Architecture" class="image is-fullwidth">
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Abstract Section -->
  <section class="section pt-0 pb-0">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Abstract</h2>
      <div class="content has-text-justified">
        <p>
          This study introduces <span class="dnerf">IRL-DAL</span> (Inverse Reinforcement Learning with a Diffusion-based Adaptive Lookahead planner), 
          an integrated framework that unites reinforcement learning with generative trajectory planning for autonomous driving. 
          At its foundation lies the Diffusion-based Adaptive Lookahead (DAL) planner — a conditional diffusion model designed to generate safe and 
          dynamically feasible motion trajectories governing both steering and velocity control.
        </p>

        <figure class="is-pulled-right ml-4 mb-2" style="max-width: 45%; border-radius: 12px; overflow: hidden; box-shadow: 0 4px 12px rgba(0,0,0,0.1);">
          <video width="100%" controls>
            <source src="model.mp4" type="video/mp4">
            مرورگر شما از پخش ویدیو پشتیبانی نمی‌کند.
          </video>
        </figure>

        <p>
          Distinct from conventional sampling approaches, DAL operates in a classifier-free mode guided by a multi-objective energy function. 
          This function automatically balances lane keeping, obstacle avoidance, and control stability in response to real-time perceptual signals, 
          allowing the agent to emphasize safety under challenging conditions without compromising efficiency.
        </p>
        
        <p>
          To address sample inefficiency and promote stable policy convergence, training proceeds through a two-stage curriculum implemented 
          in the Webots simulator. The process begins with Behavioral Cloning (BC) for policy initialization and transitions to 
          Proximal Policy Optimization (PPO) for refinement. During the PPO stage, a hybrid reward formulation merges sparse environmental feedback 
          with a dense, learned reward obtained via Inverse Reinforcement Learning (IRL), thereby encouraging expert-level driving behavior.
        </p>
        
        <p>
          Comprehensive simulation results show that <span class="dnerf">IRL-DAL</span> consistently surpasses standard baselines in terms of safety, 
          control smoothness, and task completion. These findings validate the proposed framework's capability to produce robust, precise, and 
          safety-compliant driving policies suitable for deployment in safety-critical autonomous systems.
        </p>
      </div>
    </div>
  </section>

  <!-- Main Content -->
  <section class="section">
    <div class="container is-max-desktop">
      <!-- Performance Comparison -->
      <div class="columns is-centered">
        <div class="column is-full">
          <h2 class="title is-3 has-text-centered">Performance Comparison</h2>
          <div class="paper-table">
            <table class="table is-bordered is-fullwidth is-hoverable">
              <thead>
                <tr>
                  <th class="has-text-centered">Model</th>
                  <th class="has-text-centered">Mean Reward &uarr;</th>
                  <th class="has-text-centered">Coll./1k Steps &darr;</th>
                  <th class="has-text-centered">Success (%) &uarr;</th>
                  <th class="has-text-centered">BC Loss (&times;10<sup>-2</sup>) &darr;</th>
                  <th class="has-text-centered">Action Sim. (%) &uarr;</th>
                  <th class="has-text-centered">ADE (m) &darr;</th>
                  <th class="has-text-centered">FDE (m) &darr;</th>
                </tr>
              </thead>
              <tbody class="has-text-centered">
                <tr>
                  <td class="has-text-left">PPO + Uniform Sampling</td>
                  <td>85.2 &plusmn; 4.1</td>
                  <td>0.63 &plusmn; 0.12</td>
                  <td>78.1 &plusmn; 3.2</td>
                  <td>17.1 &plusmn; 1.4</td>
                  <td>65.3 &plusmn; 4.1</td>
                  <td>5.25 &plusmn; 0.31</td>
                  <td>11.8 &plusmn; 0.65</td>
                </tr>
                <tr>
                  <td class="has-text-left">+ FSM Replay</td>
                  <td>120.4 &plusmn; 3.8 <span class="pct-improve">(+41%)</span></td>
                  <td>0.30 &plusmn; 0.08</td>
                  <td>88.4 &plusmn; 2.1</td>
                  <td>12.3 &plusmn; 1.1</td>
                  <td>75.1 &plusmn; 3.5</td>
                  <td>4.10 &plusmn; 0.27</td>
                  <td>9.5 &plusmn; 0.58</td>
                </tr>
                <tr>
                  <td class="has-text-left">+ Diffusion Planner</td>
                  <td>155.1 &plusmn; 3.2 <span class="pct-improve">(+29%)</span></td>
                  <td>0.15 &plusmn; 0.05</td>
                  <td>92.0 &plusmn; 1.8</td>
                  <td>13.0 &plusmn; 1.0</td>
                  <td>80.2 &plusmn; 3.0</td>
                  <td>3.15 &plusmn; 0.22</td>
                  <td>7.2 &plusmn; 0.49</td>
                </tr>
                <tr class="is-selected" style="font-weight: bold;">
                  <td class="has-text-left">+ LAM + SAEC (Ours)</td>
                  <td>180.7 &plusmn; 2.9 <span class="pct-improve">(+16%)</span></td>
                  <td>0.05 &plusmn; 0.03</td>
                  <td>96.3 &plusmn; 1.2</td>
                  <td>7.4 &plusmn; 0.8</td>
                  <td>85.7 &plusmn; 2.4</td>
                  <td>2.45 &plusmn; 0.18</td>
                  <td>5.1 &plusmn; 0.41</td>
                </tr>
              </tbody>
            </table>
            <p class="is-size-7 has-text-grey has-text-centered mt-3">
              Quantitative performance across architectural variants (10 seeds, mean &plusmn; std). Mean reward normalized to [0, 200]. 
              Trajectory prediction metrics (ADE/FDE) from rollout evaluation. Arrows indicate improvement direction; <strong>bold</strong> denotes best.
            </p>
          </div>
        </div>
      </div>

<!-- Key Components Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="content">
      
      <!-- Two-Phase Curriculum & Diffusion Planner Row -->
      <div class="columns is-centered">
        
        <!-- Column 1: Two-Phase Training Curriculum -->
        <div class="column">
          <h3 class="title is-4 has-text-centered">Two-Phase Training Curriculum</h3>
          <div class="content has-text-justified">
            <p>
              To ensure stable convergence and sample efficiency, our agent is trained via a two-phase curriculum. <strong>Phase 1 (Behavioral Cloning)</strong> involves pre-training the policy for 20,000 steps using an expert dataset generated by a Finite State Machine (FSM). This establishes a robust behavioral prior, teaching the agent fundamental driving skills. <strong>Phase 2 (IRL-PPO)</strong> fine-tunes the policy for 30,000 steps using a hybrid reward signal. This signal combines sparse task rewards with a dense, GAIL-based imitation reward, encouraging the agent to explore complex scenarios while adhering to expert-like decision-making.
            </p>
          </div>
          <img src="fsm.png" alt="Training Curriculum Diagram" class="image is-fullwidth">
        </div>

        <!-- Column 2: Energy-Guided Diffusion Planner -->
        <div class="column">
          <h3 class="title is-4 has-text-centered">Energy-Guided Diffusion Planner</h3>
          <div class="content has-text-justified">
            <p>
              The Diffusion Planner acts as a critical, on-demand safety module. It is activated only in high-risk states identified by the base policy, making it computationally efficient. Upon activation, it generates a set of safe, short-horizon trajectories. The optimal trajectory is selected via a multi-objective energy function that expertly balances three critical goals: <strong>lane adherence</strong> to maintain course, <strong>obstacle avoidance</strong> for collision prevention, and <strong>control smoothness</strong> (jerk minimization) to ensure passenger comfort and stability.
            </p>
          </div>
          <!-- Note: Make sure the image dimensions are appropriate for the layout -->
          <img src="trajectory.png" alt="Energy-Guided Trajectory Planning" class="image is-fullwidth">
        </div>
      </div>

      <!-- Learnable Adaptive Mask (LAM) Row -->
      <div class="columns is-centered">
        <div class="column is-full">
          <h2 class="title is-3 has-text-centered">Learnable Adaptive Mask (LAM)</h2>
          <div class="content has-text-justified">
            <p>
              The Learnable Adaptive Mask (LAM) is a state-aware perception module designed for intelligent allocation of visual attention. It dynamically adjusts the agent's perceptual focus based on real-time driving context. At high speeds, rather than expanding to the horizon, LAM actively <strong>amplifies the lower visual field</strong> (near-field road features) to ensure precise lane tracking and lateral stability. Conversely, when LiDAR detects nearby hazards or in dense traffic, the mask intensifies focus on the immediate surroundings to facilitate rapid collision avoidance, offering an interpretable and efficient alternative to heavy self-attention layers.
            </p>
          </div>
          <img src="attention.png" alt="Learnable Adaptive Mask Visualization" class="image is-fullwidth">
        </div>
      </div>

      <!-- Key Contributions Row -->
      <div class="columns is-centered">
        <div class="column is-full">
          <h2 class="title is-3 has-text-centered">Key Contributions</h2>
          <div class="content">
            <p>Our work introduces several novel contributions to the field of autonomous driving:</p>
            <ul>
              <li>
                <strong>Hybrid Learning Synthesis:</strong> A novel training framework that synergizes Behavioral Cloning for stable initialization, Inverse Reinforcement Learning (via GAIL) for dense, expert-aligned reward shaping, and Proximal Policy Optimization for robust exploration and refinement.
              </li>
              <li>
                <strong>Diffusion Planning as a Corrective Safety Layer:</strong> The first application of a conditional diffusion model as an on-demand, corrective safety planner for an active RL agent, ensuring safety compliance without stifling the policy's learning and exploration process.
              </li>
              <li>
                <strong>State-Guided Adaptive Perception:</strong> A lightweight and interpretable attention mechanism (LAM) that dynamically modulates feature extraction. It prioritizes <strong>near-field lane coherence</strong> during high-speed driving for lateral stability and highlights proximate surroundings when hazards are detected, ensuring efficient and context-aware visual processing.
              </li>
              <li>
                <strong>Safety-Aware Experience Correction (SAEC):</strong> A novel feedback loop where interventions from the safety planner are not discarded but are distilled into structured learning experiences. This allows the RL policy to learn directly from its near-failures, progressively enhancing its intrinsic safety.
              </li>
            </ul>
          </div>
        </div>
      </div>
      
    </div>
  </div>
</section>


  <!-- BibTeX Section -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
    </div>
  </section>

  <!-- JavaScript -->
  <script>
    // Navbar Mobile Toggle
    document.addEventListener('DOMContentLoaded', () => {
      const $navbarBurgers = Array.prototype.slice.call(document.querySelectorAll('.navbar-burger'), 0);
      
      if ($navbarBurgers.length > 0) {
        $navbarBurgers.forEach(el => {
          el.addEventListener('click', () => {
            const target = el.dataset.target;
            const $target = document.getElementById(target);
            
            el.classList.toggle('is-active');
            $target.classList.toggle('is-active');
          });
        });
      }
    });

    // Carousel Functionality
    let currentSlide = 0;
    const slides = document.querySelectorAll('.carousel .item');
    
    function nextSlide() {
      slides[currentSlide].classList.remove('active');
      currentSlide = (currentSlide + 1) % slides.length;
      slides[currentSlide].classList.add('active');
    }
    
    function prevSlide() {
      slides[currentSlide].classList.remove('active');
      currentSlide = (currentSlide - 1 + slides.length) % slides.length;
      slides[currentSlide].classList.add('active');
    }
    
    // Auto-advance carousel every 5 seconds
    setInterval(nextSlide, 5000);
    
    // Initialize first slide
    if (slides.length > 0) {
      slides[0].classList.add('active');
    }
  </script>
</body>
</html>
